{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we may need deeper networks so that some features have broader receptive fields, can learn features that are functions of a greater portion of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding and Stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function from previous notebook\n",
    "# Converting to function for future use, default num_workers is 4 bc CPU threads\n",
    "def load_fashion_mnist(batch_size: int = 512, num_workers: int = 4):\n",
    "    data_transform = transforms.ToTensor() # Obtaining data to tensor converter\n",
    "    \n",
    "    # Downloading data\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root = \"../data\", train = True, transform = data_transform, download= True)  # Defining fashion MNIST train from torch datasets\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root = \"../data\", train = False, transform = data_transform, download = True)\n",
    "    \n",
    "    # Loading data onto an iterator\n",
    "    train_data_loader = data.DataLoader(mnist_train, batch_size, shuffle = True, num_workers = 4)\n",
    "    test_data_loader = data.DataLoader(mnist_test, batch_size, shuffle = True, num_workers = 4)\n",
    "    \n",
    "    # Returning iterator\n",
    "    return train_data_loader, test_data_loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gilpasternak/Library/Python/3.8/lib/python/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = load_fashion_mnist() # Checking label shape for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "tensor(9)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(2)\n",
      "tensor(6)\n",
      "tensor(5)\n",
      "tensor(8)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(6)\n",
      "tensor(4)\n",
      "tensor(7)\n",
      "tensor(1)\n",
      "tensor(4)\n",
      "tensor(1)\n",
      "tensor(4)\n",
      "tensor(0)\n",
      "tensor(5)\n",
      "tensor(4)\n",
      "tensor(3)\n",
      "tensor(9)\n",
      "tensor(1)\n",
      "tensor(5)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(9)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(3)\n",
      "tensor(4)\n",
      "tensor(7)\n",
      "tensor(8)\n",
      "tensor(5)\n",
      "tensor(0)\n",
      "tensor(1)\n",
      "tensor(4)\n",
      "tensor(9)\n",
      "tensor(2)\n",
      "tensor(1)\n",
      "tensor(6)\n",
      "tensor(8)\n",
      "tensor(5)\n",
      "tensor(4)\n",
      "tensor(7)\n",
      "tensor(4)\n",
      "tensor(9)\n",
      "tensor(7)\n",
      "tensor(9)\n",
      "tensor(4)\n",
      "tensor(5)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(0)\n",
      "tensor(5)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(5)\n",
      "tensor(4)\n",
      "tensor(8)\n",
      "tensor(4)\n",
      "tensor(7)\n",
      "tensor(9)\n",
      "tensor(6)\n",
      "tensor(6)\n",
      "tensor(3)\n",
      "tensor(9)\n",
      "tensor(0)\n",
      "tensor(9)\n",
      "tensor(3)\n",
      "tensor(4)\n",
      "tensor(6)\n",
      "tensor(4)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(9)\n",
      "tensor(5)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(2)\n",
      "tensor(4)\n",
      "tensor(6)\n",
      "tensor(1)\n",
      "tensor(5)\n",
      "tensor(6)\n",
      "tensor(8)\n",
      "tensor(7)\n",
      "tensor(9)\n",
      "tensor(5)\n",
      "tensor(2)\n",
      "tensor(8)\n",
      "tensor(2)\n",
      "tensor(8)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(2)\n",
      "tensor(6)\n",
      "tensor(4)\n",
      "tensor(8)\n",
      "tensor(6)\n",
      "tensor(5)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(6)\n",
      "tensor(7)\n",
      "tensor(2)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(0)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(8)\n",
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "for i,x in train_loader:\n",
    "    print(x[0]) # First label for each batch - label is a single value!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Padding** - adding a layer of zeros around the perimeter of an image so that, as networks grow deeper and receptive fields grow larger, we do not lose edge information entirely in a cocophony of aggregations that consistently favors the greater number of logits in the image center. Padding adds 0 information (in aggregations it has no effect) yet allows for aggregations that involve explicitly edge information, hence capturing valuable aggregations that have a receptive field of only the image edge.\n",
    "\n",
    "Change to output dimensionality: by adding a padding layer we add p rows and z columns to the input image, and hence an identical number to the output: xrows - kernel rows + p rows +1 x xcolumns -kernel columns + z columns + 1 (same k-1 unreachable convolutions off ideology for kernel but image now augmented by p rows and z columns)\n",
    "\n",
    "Padding often symmetrical so as to capture equivalent edge information around the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often choose odd sized Kernels as seek to occasionally preserve dimensionality when aggregating information. How? even len - odd_kernel + 1 = even_new_len, + symmetrical padding (to capture equal edge information) = original_len. Why? Offers benefit that any vlaue in the transformation y[i,j] is cross_corr?(kernel, part of x centered at x[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proof of concept of the above statement - padded tensor\n",
    "t1 = torch.Tensor([[0,0,0,0,0],[0,1,2,3,0], [0,2,3,4,0], [0,3,4,5,0], [0,0,0,0,0]])\n",
    "kernel = torch.Tensor([[0,1,2], [0,1,2], [0,1,2]]) # Right information most important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_cor(t1: torch.Tensor, kernel: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Applies a kernel filter across a tensor, producing an aggregated latent representation\"\"\"\n",
    "    # New shape is how far short of endpoint filter must stop (because it cannot exceed boundaries of image) + 1 for the stopping iteration (if it is sized 2, it still aggregates when 2 away from edge)\n",
    "    new_shape = t1.shape[0] - kernel.shape[0] + 1, t1.shape[1] - kernel.shape[1] + 1\n",
    "    # A latent representation of aggregated localities\n",
    "    latent_representation = torch.rand(new_shape[0], new_shape[1]) # Using image dimensions\n",
    "    # Iterating and cross correlating\n",
    "    for i in range(new_shape[0]):\n",
    "        for j in range(new_shape[1]):\n",
    "            # Will dot tensors together via multiplication operator - this is the default\n",
    "            # Obtaining locality, using stride of 1, of sized kernel. Convoluted along\n",
    "            inter_tensor = t1[i:i+ kernel.shape[0], j:j+kernel.shape[1]]\n",
    "            # Obtaining cross correlation of locality with kernel (using kernel to weigh sum of information in locality)\n",
    "            weighted_locality_rep = (inter_tensor * kernel).sum() # Aggregating weighted feature information (reduces latent space rather than just weights)\n",
    "            latent_representation[i][j] = weighted_locality_rep\n",
    "    return latent_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0., 0.],\n",
       "         [0., 1., 2., 3., 0.],\n",
       "         [0., 2., 3., 4., 0.],\n",
       "         [0., 3., 4., 5., 0.],\n",
       "         [0., 0., 0., 0., 0.]]),\n",
       " tensor([[0., 1., 2.],\n",
       "         [0., 1., 2.],\n",
       "         [0., 1., 2.]]),\n",
       " tensor([[13., 19.,  7.],\n",
       "         [24., 33., 12.],\n",
       "         [19., 25.,  9.]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1, kernel, cross_cor(t1, kernel) # Padding ompensates for 1/2 Kernel height, rendering every right shifted element centered\n",
    "# t1 + p(len(k)/2) * k (crosses 1/2 of p, either kernel present or padding allows kernel to be centered initially)\n",
    "# This is a functional benefit as we know that input centric edge features are directly convoluted to the output image, with identical dimensionality preserved, \n",
    "# requires: p = k-1 so then n-k+1 + (k-1) = n = original dimensions\n",
    "# When Kernel not a square matrix, can set different padding values on height and width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetPadding(torch.nn.Module):\n",
    "    def __init__(self, *dims):\n",
    "        # Weigh + aggregate information twice by convolving it with a localized weighting kernel, then map to output space\n",
    "        # Call to parent constructor initializes modules\n",
    "        super().__init__()\n",
    "        self._modzules[\"layer_1\"] = torch.nn.Conv2d(1,1, kernel_size = (14,14), padding = (1,1))\n",
    "        self._modules[\"layer_2\"] = torch.nn.Conv2d(1,1, kernel_size = (10,10), padding = (1,1)) \n",
    "        # Previous error: thought labels were 10 class probabilities, turns out we want concrete prediction\n",
    "        self._modules[\"remaining_network\"] = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(100,10))\n",
    "        \n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Instance method defining computational mapping to output space\"\"\"\n",
    "        X = torch.nn.functional.relu(self._modules[\"layer_1\"](X))\n",
    "        X = torch.nn.functional.relu(self._modules[\"layer_2\"](X))\n",
    "        # Convolving, breaking linearity, flattening, mapping to output space\n",
    "        X = self._modules[\"remaining_network\"](X)\n",
    "        # Returning result\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying init to model to initialize all layer weights\n",
    "def build_convnet():\n",
    "    # Kernels are iterating across all three dimensions and all batch sizes simultaneously\n",
    "    model = ConvNetPadding()\n",
    "    trainer = torch.optim.Adam(model.parameters(), lr = 0.005)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    return model, trainer, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, cost = build_convnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: torch.nn.Module, optimizer, cost, train_loader, epochs: int = 5):\n",
    "    for epoch in range(epochs):\n",
    "        for data, labels, in train_loader: # Returns data, label tuple\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Obtaining cross entropy cost\n",
    "            loss = cost(model(data), labels)\n",
    "            \n",
    "            # Displaying for first epoch\n",
    "            if epoch == 0:\n",
    "                print(\"cost: \", loss)\n",
    "                \n",
    "            # Resetting gradient\n",
    "            # Computing gradients\n",
    "            loss.backward()\n",
    "            # Displaying cost every 10 iterations\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Printing cost every 10th epoch\n",
    "        print(\"cost: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(2.3071, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.3009, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.2959, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.2916, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.2831, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.2829, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.2658, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.2509, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.2708, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.2399, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.2319, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.2248, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.2076, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.1902, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.1850, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.1495, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.1392, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.1012, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.0740, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.0226, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9835, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9708, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8841, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8341, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7830, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7836, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7107, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6680, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.5884, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.5745, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.4925, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.5698, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.5082, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.4797, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.4257, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.4095, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.4148, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.4333, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.3862, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.3984, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.3944, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.4048, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.3001, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.3459, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.3071, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.2742, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.2354, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.2010, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.2967, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.1844, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.1960, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.1596, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.2180, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.1165, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.1441, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.1071, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.1830, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.1331, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.1009, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.1287, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.1556, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.0209, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9303, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.0681, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9756, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.0422, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9838, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.0482, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.0413, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.0374, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.0761, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9883, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9781, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9905, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.0059, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.0239, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9659, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.1001, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.0465, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9256, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.0357, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9831, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.0348, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8507, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.0255, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9424, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9408, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.0057, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8860, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9567, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9689, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8933, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8982, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8932, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9157, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8821, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9231, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9546, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8928, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8714, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8178, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9012, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9230, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8554, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9729, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7839, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8473, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9023, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8017, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9221, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8619, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8600, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9070, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9609, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8320, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8301, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8539, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7995, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7995, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6815, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6332, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5879, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.4785, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "train_model(model, optimizer, cost, train_loader, 5) # Accuracy much better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Major performance boost with padding - edge features likely valueable sufficiently to the point where a kernel more centered around edge information (reduction of 14x14 is drastic and loses half of image) is more valuable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if even more padding contributes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetPadding(torch.nn.Module):\n",
    "    def __init__(self, *dims):\n",
    "        # Weigh + aggregate information twice by convolving it with a localized weighting kernel, then map to output space\n",
    "        # Call to parent constructor initializes modules\n",
    "        super().__init__()\n",
    "        self._modules[\"layer_1\"] = torch.nn.Conv2d(1,1, kernel_size = (14,14), padding = (2,2)) # Reduction to 20x20 localized features with edge info, 1 off padding\n",
    "        self._modules[\"layer_2\"] = torch.nn.Conv2d(1,1, kernel_size = (10,10), padding = (2,2)) # Reduction to 14x14 localized features with edge info\n",
    "        self._modules[\"layer_3\"] = torch.nn.Conv2d(1,1, kernel_size = (9,9), padding = (2,2)) # Receptive field now does not aggregate away edge info entirely\n",
    "        \n",
    "        # Previous error: thought labels were 10 class probabilities, turns out we want concrete prediction\n",
    "        self._modules[\"remaining_network\"] = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(100,10))\n",
    "        \n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Instance method defining computational mapping to output space\"\"\"\n",
    "        X = torch.nn.functional.relu(self._modules[\"layer_1\"](X))\n",
    "        X = torch.nn.functional.relu(self._modules[\"layer_2\"](X))\n",
    "        X = torch.nn.functional.relu(self._modules[\"layer_3\"](X))\n",
    "        # Convolving, breaking linearity, flattening, mapping to output space\n",
    "        X = self._modules[\"remaining_network\"](X)\n",
    "        # Returning result\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, cost = build_convnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(0.5682, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5926, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5861, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6680, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6007, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5969, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6198, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5877, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5558, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6123, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6031, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5890, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6380, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5951, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5767, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6086, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7384, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5012, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6455, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5381, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5320, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5813, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.4896, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5279, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6267, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5737, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.4977, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5662, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5449, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5237, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6163, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5863, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5573, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5912, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5447, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5785, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5425, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5825, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5082, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5854, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6003, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5349, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5428, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5273, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5792, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5757, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6569, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5658, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5683, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6636, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5641, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5275, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6048, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5922, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5700, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5845, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5249, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5420, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5876, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6130, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6042, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6103, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5844, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.4722, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.4947, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6122, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5812, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6088, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5687, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5249, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6123, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5172, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5062, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5760, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5656, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5657, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.4833, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5487, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6127, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6020, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5043, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5691, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5570, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6628, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5545, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5889, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5638, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5668, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5412, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5858, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5734, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5669, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5864, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5928, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6003, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5879, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6226, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7221, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5217, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5362, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5211, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5638, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5792, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5295, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5461, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6101, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6322, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5362, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5645, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5396, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5915, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5553, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6231, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6582, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6034, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5842, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5618, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6412, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6412, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5541, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5904, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5826, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.3997, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "train_model(model, optimizer, cost, train_loader, 5) # Model appears to perform better with better edge features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model: torch.nn.Module, cost, test_loader):\n",
    "    total_loss = torch.Tensor([0])\n",
    "    # Computing #batches\n",
    "    batch_num = 0\n",
    "    for data, labels, in test_loader: # Returns data, label tuple\n",
    "        batch_num+=1\n",
    "        # Ensuring gradient is not computed\n",
    "        with torch.no_grad():\n",
    "            # Obtaining cross entropy cost\n",
    "            loss = cost(model(data), labels)\n",
    "            total_loss += loss.sum()\n",
    "    return total_loss/batch_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5569])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, cost, test_loader) # Scales pretty nicely to test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use stride to downsample (view sparsely sampled parts of image) or reduce latent shape for the sake of computational efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can stride in different shapes vertically and horizontally, reducing latent dimensions in uneven manner. The reduction to a dimension nk = (nk - k + p + s) / s = (nk-k+p / s) + 1 as stride does not change initial \"fit\", so the if an array has 6 elements with a stride of 2, kernel of 2, padding of 2: 6 - 2 + 2 / 2 + 1 = 4. This is because stride evenly divides the number of elements (downsampling by 1/k), padding adds m elements to nk, and kernels subtract k-1 elements away - hence the need for the +s/s or the +1 in order to compensate for the fact that kernels enumerate their last fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing stride in a neural network: attempt\n",
    "class ConvNetPaddingStride(torch.nn.Module):\n",
    "    def __init__(self, *dims):\n",
    "        # Weigh + aggregate information twice by convolving it with a localized weighting kernel, then map to output space\n",
    "        # Call to parent constructor initializes modules\n",
    "        super().__init__()\n",
    "        self._modules[\"layer_1\"] = torch.nn.Conv2d(1,1, kernel_size = (14,14), padding = (2,2)) # Reduction to 20x20 localized features with edge info, 1 off padding\n",
    "        self._modules[\"layer_2\"] = torch.nn.Conv2d(1,1, kernel_size = (8,8), padding = (2,2)) # Reduction to 16x16 localized features with edge info\n",
    "        self._modules[\"layer_3\"] = torch.nn.Conv2d(1,1, kernel_size = (5,5), padding = (2,2), stride = (2,2)) # Receptive field now does not aggregate away edge info entirely\n",
    "        \n",
    "        # Previous error: thought labels were 10 class probabilities, turns out we want concrete prediction\n",
    "        self._modules[\"remaining_network\"] = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(64,10))\n",
    "        \n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Instance method defining computational mapping to output space\"\"\"\n",
    "        X = torch.nn.functional.relu(self._modules[\"layer_1\"](X))\n",
    "        X = torch.nn.functional.relu(self._modules[\"layer_2\"](X))\n",
    "        X = torch.nn.functional.relu(self._modules[\"layer_3\"](X))\n",
    "        # Convolving, breaking linearity, flattening, mapping to output space\n",
    "        X = self._modules[\"remaining_network\"](X)\n",
    "        # Returning result\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying init to model to initialize all layer weights\n",
    "def build_convnet_stride():\n",
    "    # Kernels are iterating across all three dimensions and all batch sizes simultaneously\n",
    "    model = ConvNetPaddingStride()\n",
    "    trainer = torch.optim.Adam(model.parameters(), lr = 0.005)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    return model, trainer, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, cost = build_convnet_stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(2.3062, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.3029, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.3035, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.2981, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.3017, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.2994, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.2860, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.2746, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.2495, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.2227, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.1881, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.1469, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.0479, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.0112, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9069, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7843, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7078, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6416, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.5398, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.4760, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.3184, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.3856, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.2115, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.3877, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.2312, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.2290, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.0930, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.3089, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.0429, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.0007, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.0389, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.0910, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.0170, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8978, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9966, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9508, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.0094, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9451, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.0108, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9531, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9280, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.9117, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8855, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8898, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8143, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8054, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8462, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7872, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7083, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7626, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8475, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7799, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8180, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8353, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7713, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8173, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8026, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7451, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8232, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7452, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8159, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7775, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6781, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7486, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8171, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6859, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7390, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7300, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7710, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7694, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7223, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7279, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7179, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6884, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7921, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6087, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7494, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6616, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6959, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6107, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7510, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7019, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6851, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6919, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7322, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6282, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6662, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7130, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7472, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7231, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7225, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6675, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6852, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7088, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6895, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7085, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6958, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7225, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.8003, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7075, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6433, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6579, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7018, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5921, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6707, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7355, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6867, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6804, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6894, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6760, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6231, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7096, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7550, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6740, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7401, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6607, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7387, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6571, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6571, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.6304, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.4843, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.7074, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(0.5645, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "train_model(model, optimizer, cost, train_loader, 5) # In Downsampling data in last layer, we are likely downsampling some features, hence training a worse NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
