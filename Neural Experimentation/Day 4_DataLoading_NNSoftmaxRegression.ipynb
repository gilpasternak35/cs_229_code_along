{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.ToTensor() # Obtaining data to tensor converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gilpasternak/Library/Python/3.8/lib/python/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "mnist_train = torchvision.datasets.FashionMNIST(root = \"../data\", train = True, transform = data_transform, download= True)  # Defining fashion MNIST train from torch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gilpasternak/Library/Python/3.8/lib/python/site-packages/torchvision/datasets/mnist.py:52: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([9, 0, 0,  ..., 3, 0, 5]),\n",
       " Dataset FashionMNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: ../data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: ToTensor())"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train.train_labels, mnist_train # Get back a class that contains training data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test = torchvision.datasets.FashionMNIST(root = \"../data\", train = False, transform = data_transform, download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ../data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_test # Test set Tensor transformed display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Data Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "# Defining iterator to iterate through training set\n",
    "train_data_loader = data.DataLoader(mnist_train, batch_size, shuffle = True, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining identical data loader fo test set\n",
    "test_data_loader = data.DataLoader(mnist_test, batch_size, shuffle = True, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to function for future use, default num_workers is 4 bc CPU threads\n",
    "def load_fashion_mnist(batch_size: int = 512, num_workers: int = 4):\n",
    "    data_transform = transforms.ToTensor() # Obtaining data to tensor converter\n",
    "    \n",
    "    # Downloading data\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root = \"../data\", train = True, transform = data_transform, download= True)  # Defining fashion MNIST train from torch datasets\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root = \"../data\", train = False, transform = data_transform, download = True)\n",
    "    \n",
    "    # Loading data onto an iterator\n",
    "    train_data_loader = data.DataLoader(mnist_train, batch_size, shuffle = True, num_workers = 4)\n",
    "    test_data_loader = data.DataLoader(mnist_test, batch_size, shuffle = True, num_workers = 4)\n",
    "    \n",
    "    # Returning iterator\n",
    "    return train_data_loader, test_data_loader \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Regression Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, test_iter = load_fashion_mnist(128, 4) # Loading train and test iterators for softmax implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax regression: map from an input to label probabilities (class confidences) in continuous space\n",
    "# Regress using gradient towards a solution which minimizes error.\n",
    "\n",
    "# Will flatten input image\n",
    "input_img_size = 784\n",
    "output_space = 10\n",
    "\n",
    "# need to use weights to map from input space (784) to output space (each of 10 cols weights 784 pixels in a featurous way so as to produce output)\n",
    "w = torch.normal(0, 0.1, (input_img_size, output_space), requires_grad = True) # Initializing around 0 (with a small SD so not exactly)\n",
    "b = torch.zeros(output_space, requires_grad = True) # want each neuron to have a linear bias shifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[35.0000, 36.2000, 13.1000]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick summing review: remember that largest dim = innermost/ most nested dim\n",
    "X = torch.Tensor([[1.0, 2.0, 3.0], [7.0, 8.0, 9.0], [27.0, 26.2, 1.1]])\n",
    "X.sum(0, keepdims = True) # Allows maintanence of nested dimension even though it has collapsed (there is no need for it, it is 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[84.3000]]), tensor(84.3000), tensor(84.3000))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum((0,1), keepdims = True), X.sum((0,1)), X.sum() # Collapse dimension removes uneccessary \n",
    "# dim = 1, no collapse => remains nested, otherwise total sum will yield a scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick conceptual understanding of sums**:\n",
    "\n",
    "If the largest dimension is the innermost, that can be thought of as a row/record in which the values belong in 1 dimensional data, in 2 dimensional data this is the last 2 dimensions. The representation of a record can be summed across all records which is the next most nested dimension, which could then be summed across all tables (3rd most inner dimension). Hence summing across the final 2 dims in 1D data is summing across the whole table. Keep dimension simply groups all summed attributes in a single attribute and does not delete it due to uselessness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X: torch.Tensor):\n",
    "    # Mapped to the positive space with the magnitudinal differences of the exponential\n",
    "    exponentiated_activations = torch.exp(X)\n",
    "    sum_exponentiated_activations = exponentiated_activations.sum(1, keepdims = True)\n",
    "    \n",
    "    # Note: put under complex variable names for understanding\n",
    "    mapped_probabilities = exponentiated_activations/sum_exponentiated_activations\n",
    "    return mapped_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0785, 0.2133, 0.7082]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(torch.Tensor([[0.2, 1.2, 2.4]])) # Exponential differences in confidence visible (+ 1 =occupies 2.7x more of exponentiated sum)\n",
    "# Benefits of softmax - maps to 0,1 space but assigns tiny probabilities to negative activations relative to positive if positive exist, order of magnitude less\n",
    "# Maps relative to other confidences\n",
    "# Assigns non-negligible probabilities to every event but shows initial confidence in high activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy = sum(predictions == lables) / # of labels = rate of correctness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All layer names are in torch.nn and are capitalized\n",
    "model = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(input_img_size, output_space), torch.nn.Softmax()) # Autoflatten data to 1D layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a trainer\n",
    "trainer = torch.optim.AdamW(model.parameters(), lr = 0.03)\n",
    "loss = torch.nn.CrossEntropyLoss() #losses in torch.nn, just as layers are, also capitalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "  (2): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing weights randomly and applying to Neural Network\n",
    "# PyTorch apply works on a per-layer basis\n",
    "def init_weights(layer: torch.nn):\n",
    "    if isinstance(layer, torch.nn.Linear): # Note: weight used, not weights in plural in pytorch\n",
    "        # init.normal initializes any torch layer parameter with normally distributed values\n",
    "        torch.nn.init.normal_(layer.weight, mean = 0, std = 0.1) # Initializing normal weights by default, bias is 0   \n",
    "\n",
    "model.apply(init_weights) # Autoinitialize any linear weights with normal inputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1425,  0.1607,  0.0053,  ..., -0.2733,  0.1425, -0.0251],\n",
       "        [-0.1442, -0.0463, -0.0375,  ...,  0.0690,  0.0218,  0.1156],\n",
       "        [ 0.0027,  0.1169,  0.0535,  ...,  0.1093,  0.0006,  0.0294],\n",
       "        ...,\n",
       "        [ 0.0833, -0.0157,  0.1100,  ..., -0.0693,  0.0212, -0.1627],\n",
       "        [-0.1634, -0.0866, -0.0770,  ...,  0.1341, -0.0088, -0.2158],\n",
       "        [-0.1885,  0.1428, -0.0240,  ..., -0.1264,  0.0177,  0.1476]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1].weight.data # Proof of autoinitialized weights (flatten layer has no weights, naturally)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Need to avoid two phenomena with Softmax**:\n",
    "\n",
    "* Overflow could be avoided by subtracting max, which does not change magnitudal exponentiation relation between values of softmax. Subtracting a constant makes no difference.\n",
    "* Underflow, or a value being rounded to 0 and then being used in an operation where 0 is an exclusive lower bound (ex: log, division). This could be avoided by the fact that we will use cross entropy as a loss function to measure how far away the probabilities are from the true distribution, so we will be taking the log of the exponential anyway, which cancel out. We can avoid this operation by taking the log in advance and then not having to take the log of a number that has been approximated as 0, leading to NaN's\n",
    "    * Note to self: revisit cross entropy to actually understand it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(2.3461, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.2244, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.1470, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.0445, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.1250, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9709, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9371, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9221, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9895, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.0488, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.0462, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9634, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(2.0063, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9860, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7888, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8641, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8923, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9107, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8734, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8538, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9644, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8608, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8917, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7838, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8924, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8595, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8967, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9063, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8120, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8971, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7894, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8720, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9255, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8202, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9169, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8453, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9118, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9205, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7618, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8015, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8244, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8526, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9251, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8109, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8635, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8423, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8584, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7890, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9075, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8076, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8233, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8356, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8715, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8388, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7730, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7829, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7968, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9060, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8060, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9273, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8079, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9185, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8314, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7957, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8493, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7739, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8525, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8961, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8372, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8847, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8936, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9112, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8319, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8319, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9044, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8919, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8697, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8897, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8682, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7680, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7821, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9057, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8261, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8376, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8510, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8440, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8370, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8104, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8328, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8776, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7399, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8616, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8979, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8396, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8517, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8814, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8104, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8534, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8366, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8638, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8593, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8495, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8469, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8387, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8104, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8942, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8926, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8447, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8146, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8310, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8272, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8187, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8282, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8344, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7947, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7928, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8616, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8265, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8540, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9211, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8594, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7963, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8162, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7304, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7848, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8143, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8565, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8422, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8379, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7938, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8089, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8143, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8610, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8722, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8228, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8235, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8709, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8244, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8351, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8154, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8909, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8716, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7665, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8683, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8577, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8550, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7884, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8302, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8728, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8664, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9000, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8235, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7989, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7804, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7528, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7880, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7424, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8325, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7896, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8890, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7535, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8215, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8315, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7785, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8236, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8527, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8234, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8301, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7846, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8367, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8607, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8185, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7659, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7399, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8546, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8806, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8605, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7866, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8072, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8264, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8388, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8228, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8483, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(1.8143, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7965, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8528, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8447, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8019, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8363, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8517, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7745, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7815, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8099, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8159, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8480, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8558, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8057, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8349, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8090, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8438, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8259, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9170, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8247, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7715, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8114, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7967, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8753, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8111, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8803, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8288, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8534, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8195, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9202, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8487, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7523, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8291, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8525, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8200, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8858, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8146, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8696, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7721, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7794, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8481, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7895, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8300, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8081, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8310, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7928, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8869, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8647, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8283, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8192, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7990, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8342, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8533, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8098, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7114, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8121, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8199, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8271, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7946, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7037, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8060, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8174, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7738, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8195, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8723, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8585, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8175, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9199, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7767, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8818, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8260, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8253, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8178, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8229, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8607, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7522, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8692, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8127, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8613, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8429, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7401, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8593, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9014, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8925, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8253, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8196, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8246, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8864, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7475, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7995, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8716, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8679, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7907, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8258, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8100, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8593, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7578, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8165, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7821, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8875, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7446, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7836, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8052, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8666, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8373, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8403, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8295, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8869, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7981, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9044, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8115, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7893, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8331, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8158, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7915, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8001, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7952, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8656, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8189, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9002, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9128, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8382, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8640, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7597, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8201, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8893, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7448, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7834, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8247, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8685, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8555, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7931, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8086, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8291, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7870, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8457, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7958, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8814, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7624, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7899, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8504, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9150, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8163, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8423, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8663, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8320, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7620, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7963, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7547, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8245, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8201, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8249, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7846, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8620, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7716, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7916, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8047, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7548, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8208, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8386, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8569, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8292, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8215, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8311, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7752, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7862, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8205, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8274, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8883, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8350, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8849, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8308, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8145, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7888, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7865, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8051, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7800, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8217, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8596, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8352, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8368, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8579, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7853, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8329, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7987, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8146, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8077, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8388, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8216, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8529, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(1.7521, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8170, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8160, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8011, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8022, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8842, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8026, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8409, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7198, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8347, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8170, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8242, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7589, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8157, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7829, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8679, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7960, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8116, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8016, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8570, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7953, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7995, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7702, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7288, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8643, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7487, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8898, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8543, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8357, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8409, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7907, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8152, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8303, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8267, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8745, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7768, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8494, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7755, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7555, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9284, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7714, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9084, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8014, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8673, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8472, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7878, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7715, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7935, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9051, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7675, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7636, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7315, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7761, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8680, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8887, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8226, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8289, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7766, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7792, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7740, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7758, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8470, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8640, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8295, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7672, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8597, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7983, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8167, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7701, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8010, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8878, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7807, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8635, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8803, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8642, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7900, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8130, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7711, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7658, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8083, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8467, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7959, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7999, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7675, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7260, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8283, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8563, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8495, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7870, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8324, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8157, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8075, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8863, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8790, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8052, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7575, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8795, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8621, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7978, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7850, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7881, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8315, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7398, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8682, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8056, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8546, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8273, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8217, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8178, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7892, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8101, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7934, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7399, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9019, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8019, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7833, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7401, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8673, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8003, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8332, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8050, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8810, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8809, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7820, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7826, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7818, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9258, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8100, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7666, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7829, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7708, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8310, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8477, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7788, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7924, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8193, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8015, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8538, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8328, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7698, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8262, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8767, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7761, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8492, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8137, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8715, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8583, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7870, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8638, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7971, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7549, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7884, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8173, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8417, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8827, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8085, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8272, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7927, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7689, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7977, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8388, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7747, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8053, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8082, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8918, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7708, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8326, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8078, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7804, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8225, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8787, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8207, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8863, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8304, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(1.8151, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8753, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8076, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8148, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7649, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8100, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7472, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7887, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7826, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7993, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8511, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8320, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7891, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8542, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7677, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8624, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8158, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8401, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8089, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8704, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8495, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7678, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8242, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8642, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7672, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7499, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7727, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8008, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7887, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8360, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8749, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7831, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8996, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8472, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7188, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7761, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8369, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8224, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7926, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8093, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8586, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8240, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7886, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8528, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8122, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8268, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8569, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8514, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8540, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8266, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8431, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7635, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7504, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7565, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8240, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7412, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9034, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9465, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7436, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8275, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8197, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7673, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7302, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8277, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8570, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8481, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8368, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8072, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8545, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7937, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8822, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7887, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8315, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7883, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7825, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8028, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9293, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7536, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8128, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8164, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7900, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8092, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8046, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8395, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8601, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7790, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7956, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7791, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8326, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8282, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7801, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7673, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8970, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7716, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7891, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8606, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8815, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8342, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8076, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8459, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7586, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8129, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7900, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8412, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7030, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7772, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7508, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8364, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7740, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8166, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7935, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7994, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7207, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8614, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8061, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8561, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8070, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8511, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8435, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7873, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8872, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8614, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7601, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7505, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9084, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7774, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8490, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8733, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7410, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8072, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8079, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8203, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8032, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7648, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8256, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8435, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8179, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8043, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8713, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8220, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7754, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7918, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8108, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8960, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8522, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8544, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9012, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7864, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8984, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8158, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8017, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8576, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7480, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9577, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7996, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9059, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7112, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8124, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8263, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7796, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7938, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7454, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8108, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7598, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8396, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8219, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8003, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8681, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7809, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7659, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8278, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7529, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8441, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8161, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9144, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8213, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8348, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8248, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7232, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8094, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7506, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7212, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8599, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8448, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7628, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8244, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8100, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8284, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8170, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8181, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7562, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8306, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7580, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8608, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8029, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7831, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8475, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8361, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8287, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8337, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(1.8182, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8006, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8230, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7827, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7935, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8524, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8641, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8081, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7559, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8427, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7785, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8092, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7773, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7461, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7774, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7898, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8632, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8573, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8701, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8169, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8125, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8708, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8124, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8446, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7783, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8284, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8164, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8018, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8414, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7672, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8333, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7970, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8055, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8222, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8602, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7864, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8519, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7864, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8221, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9007, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8713, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7337, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7682, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8358, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8041, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7711, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8224, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8394, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8714, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7567, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7511, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8218, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8301, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8472, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7728, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8276, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8202, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7939, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8062, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7655, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9015, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7774, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7490, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8832, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8720, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8172, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7575, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7746, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8177, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8742, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8709, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8348, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7993, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8042, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8608, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8152, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7864, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7441, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7880, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7820, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8490, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8470, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7286, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8005, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8303, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8262, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7131, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8016, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8063, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7745, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8240, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9019, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8364, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8533, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8471, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8963, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8633, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8220, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8197, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7255, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8331, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8391, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7834, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8081, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8783, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8286, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8299, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8780, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7869, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8467, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7989, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7566, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7968, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8883, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7542, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7965, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8283, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8550, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8557, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8460, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7920, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8163, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7707, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7944, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8733, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8502, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7803, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8098, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8432, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7753, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7854, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8475, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7315, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7597, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8267, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7756, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8257, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8026, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8336, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8310, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8147, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9042, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7448, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8007, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8195, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8047, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7935, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8058, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8054, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8060, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8176, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7950, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7832, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8199, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7430, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7892, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7821, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8196, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8507, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7944, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7205, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8354, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8043, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8805, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8430, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8230, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8219, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8043, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8543, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8323, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8767, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7879, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8026, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8732, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8593, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7775, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8137, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8844, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8596, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8411, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8318, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8263, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7761, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7624, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7988, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8241, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7940, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7912, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8194, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8976, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8090, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(1.8378, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7978, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8478, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7868, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7702, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7453, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7943, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7892, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8178, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7296, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7676, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8091, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8634, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8393, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8241, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9340, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8790, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7407, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8026, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7998, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7645, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8373, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8130, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7755, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8655, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8332, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8710, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8720, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7756, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8047, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9149, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7647, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8128, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7858, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8743, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7824, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8857, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8036, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7912, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8097, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8116, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7979, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8633, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7932, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8715, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7994, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8367, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7813, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8480, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7926, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7779, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8681, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7628, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7620, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8401, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8311, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8755, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7922, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8443, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8271, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8307, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8311, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8605, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9034, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7892, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8358, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8425, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8266, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7920, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8017, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8767, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8146, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8105, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8324, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7756, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7746, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8288, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8548, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7912, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7977, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8129, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8311, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8206, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7855, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7727, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8477, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7813, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8273, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8058, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8519, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8311, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7584, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7617, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8583, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7845, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8977, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8167, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7744, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7504, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7723, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8364, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7623, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7714, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8506, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7882, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8469, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7641, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7727, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7175, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8192, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8429, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8265, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8796, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7797, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8203, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8470, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8032, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7574, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7476, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8058, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7969, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8518, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8368, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7912, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8465, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8417, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8026, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8234, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8028, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8185, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7997, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7796, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7729, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8052, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7759, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8105, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8170, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8225, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8412, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7799, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7958, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8952, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8545, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8422, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7609, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7861, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8065, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8312, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7860, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8319, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7725, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8490, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8732, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8315, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8089, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8403, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8402, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8340, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8324, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8169, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8775, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7897, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8422, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8979, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8550, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8024, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8485, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8518, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8085, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8308, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8303, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8119, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8110, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7202, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7840, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7966, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7874, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8216, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8635, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8827, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9483, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8351, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8185, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7481, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7851, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7696, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7727, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7968, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7579, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8090, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8323, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7471, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8100, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7733, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8528, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8577, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8006, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8038, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8679, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8203, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7988, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7971, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7910, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8187, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7915, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(1.7806, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8133, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8870, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8024, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7995, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8131, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8850, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7752, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7456, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7668, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7890, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8572, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8078, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7786, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7948, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8312, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8466, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8108, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7736, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7819, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8267, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8202, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7197, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8231, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8291, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7381, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7679, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8565, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8350, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8061, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8982, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8411, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8588, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8711, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7780, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8475, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7754, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8650, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8052, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8616, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7980, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8231, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8512, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8752, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8150, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8328, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8138, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8517, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8449, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7800, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8885, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8667, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8494, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7597, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7606, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8177, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9191, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8184, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8682, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8334, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8193, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7895, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8336, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8191, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8330, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8230, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8260, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7636, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8271, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8032, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7981, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7250, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7778, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7992, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8181, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8152, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8363, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8582, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8672, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8179, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7960, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8137, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7890, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7837, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8552, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8168, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8075, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7616, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7966, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8202, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7771, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7941, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7865, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7965, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7947, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8364, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8169, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8153, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7793, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7679, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8431, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7969, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8849, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8036, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8441, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8416, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7855, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8061, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8156, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8892, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8471, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7548, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8066, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7815, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8628, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7508, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7886, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7989, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8133, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8317, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7347, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8639, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8143, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8213, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8311, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7478, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8147, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7270, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8162, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7967, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7442, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7917, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7937, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8535, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7540, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8865, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8430, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7757, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7445, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8146, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8444, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8072, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8226, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8238, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8244, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7439, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7726, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7967, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7785, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8349, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7826, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7847, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8340, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9108, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8317, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8478, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7939, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7435, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8586, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8018, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8175, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7920, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7996, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8294, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8385, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7805, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8230, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8148, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7424, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8477, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8248, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8142, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7744, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8264, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8189, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8053, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7999, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8414, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8142, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7781, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8002, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8134, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8178, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7941, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7873, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8245, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8405, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7570, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7956, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8006, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8643, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8786, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7439, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8050, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7786, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8247, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7752, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8042, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8343, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8816, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7996, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7964, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8404, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7209, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7184, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7890, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8125, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8472, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(1.8516, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8159, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7790, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8006, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7952, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8298, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8009, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7571, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7483, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8570, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7815, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7565, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8552, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8279, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8148, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8030, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8066, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7625, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8291, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7981, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7864, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8058, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8815, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8732, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8619, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8329, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8305, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7782, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8287, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8625, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8616, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8142, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8601, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8206, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7200, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8782, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7816, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8066, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7940, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8863, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7994, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8204, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8895, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7697, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7975, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8024, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7984, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8665, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8414, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8578, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8066, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8126, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8122, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8469, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8281, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8871, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8783, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6954, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8603, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8155, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7670, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7732, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8025, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8120, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7681, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7884, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8337, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7632, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9214, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8303, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7717, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7956, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8520, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7936, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8101, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7964, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8032, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7887, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7815, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7351, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8142, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8099, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7860, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8588, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8322, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8822, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8072, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7725, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7971, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8353, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7798, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8206, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8675, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7975, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8532, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8291, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8421, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7882, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7836, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8063, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8064, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8048, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8226, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8237, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7953, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8520, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8143, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7876, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8476, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7967, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7956, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7338, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8779, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8395, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7642, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8740, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7579, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8362, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8519, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7616, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8457, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8828, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8275, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8016, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7989, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8609, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8182, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8637, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7886, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8456, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8537, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7957, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7793, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8381, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8112, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8069, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7932, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7957, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7718, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7774, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8650, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7485, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8069, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7831, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7997, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8195, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7104, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8269, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8599, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7732, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7264, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8617, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7988, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7743, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7949, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8074, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8030, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7625, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8410, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7920, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8255, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7762, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7990, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8243, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7344, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8185, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8385, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8424, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7971, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8232, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8362, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8364, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7893, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7509, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8257, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7595, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7831, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8332, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7651, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8195, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7933, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7844, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7432, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7638, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7639, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8711, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8142, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8662, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7437, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7998, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8408, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7552, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8991, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8152, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8259, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8005, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8649, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8219, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8830, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8733, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7343, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6936, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8489, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8137, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7961, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7838, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7539, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8344, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8218, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7673, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8188, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8784, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7864, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7902, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8152, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7660, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8212, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8023, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7969, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8140, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7662, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7620, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8072, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8492, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8130, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8458, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7645, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8611, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8498, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8748, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9084, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8129, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8027, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7887, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8625, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8101, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7405, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8727, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(1.7100, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7943, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8319, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8340, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8397, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8815, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8140, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8995, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8037, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8071, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8384, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8103, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7546, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8007, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8092, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9100, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7697, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7415, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7887, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8249, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8017, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7779, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8319, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8428, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8587, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9045, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8738, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7957, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7845, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8876, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7897, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8448, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8220, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8056, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7873, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8365, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8191, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7756, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8004, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7605, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8680, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8880, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8258, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8727, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8917, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7748, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8546, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8251, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7939, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7349, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8676, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7457, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8069, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8166, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7963, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8406, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7295, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8083, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8178, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8441, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7791, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8136, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8063, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8304, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7916, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8587, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8403, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8559, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7979, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8135, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7754, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7970, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8259, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8010, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8040, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8103, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7929, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7634, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7425, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8396, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7195, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7585, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7671, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7332, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8648, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8370, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8142, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8821, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7959, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8666, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8157, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8333, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8036, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8955, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8175, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8304, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7827, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7856, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7438, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8902, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8241, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8204, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8395, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7731, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9126, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8706, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8770, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7185, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8245, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8390, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8129, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8026, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8196, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8363, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7508, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8463, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8549, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8049, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7183, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8532, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8217, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8145, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8783, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8126, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8134, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7846, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8167, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7966, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8722, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7684, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7627, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7988, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7983, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8050, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8728, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8438, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8208, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8540, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7757, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8940, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8721, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8396, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7715, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8916, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8383, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8285, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8232, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8088, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8205, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8574, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8203, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8134, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8089, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8862, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7531, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7889, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8457, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7684, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7771, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7806, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7932, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8068, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7783, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8190, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7835, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8782, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8331, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8328, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8034, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7595, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8542, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7801, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8310, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7975, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7830, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8776, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7845, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8514, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8067, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7575, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8049, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7986, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8051, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7961, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8216, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8066, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8278, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8658, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7667, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8743, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8116, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8650, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7984, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8197, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(1.8497, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8580, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8011, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7811, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8229, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7865, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8715, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8063, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7815, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8075, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7680, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8014, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8452, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7481, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7889, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8342, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8563, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7989, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8449, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8425, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8335, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7460, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7652, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8393, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8666, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8028, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8574, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7845, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7576, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8461, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7973, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8019, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7501, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7788, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7973, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8056, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8175, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8400, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8188, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8247, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8662, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8768, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7936, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7568, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7861, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8287, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8264, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8523, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8373, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8341, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7823, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8415, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7712, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7749, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8591, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7976, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7821, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8588, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8293, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8761, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8458, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7952, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8069, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8138, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7832, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7322, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7696, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7733, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8439, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7803, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8277, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8277, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7543, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8299, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8277, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7802, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8455, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8092, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7983, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8096, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7680, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8593, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7850, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8049, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8525, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8479, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7717, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8661, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7905, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7987, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7906, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8347, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8088, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8167, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8794, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7986, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7994, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8337, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8258, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7657, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7594, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8090, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8899, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8065, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8507, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8303, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8195, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8327, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7410, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8068, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8634, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9648, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8436, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8294, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8053, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8494, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8201, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8307, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7605, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7969, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8850, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8449, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9127, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7345, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8170, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7565, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8144, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8060, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8432, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8553, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7536, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8284, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7961, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8195, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8374, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7561, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8583, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7351, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8405, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7937, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8115, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7743, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7497, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8040, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7913, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8738, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7896, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8354, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7490, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7749, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7587, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7930, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7885, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8852, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7116, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7857, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8620, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8216, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7412, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7979, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8671, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8891, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7590, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8158, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7626, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8554, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.9059, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8359, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8309, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8220, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7820, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8741, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8224, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8691, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7843, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8277, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8054, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8509, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7332, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7917, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8274, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(1.8177, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7702, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8950, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7996, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8096, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7742, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8755, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7780, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8023, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8330, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8606, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7499, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8417, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8010, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8462, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7819, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7958, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8117, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8075, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7895, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8429, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8467, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8246, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7603, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7420, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7463, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7347, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8497, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8357, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7432, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8027, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8238, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7106, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8380, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7610, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6447, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7027, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7397, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7137, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7117, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7113, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7487, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7024, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7514, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8055, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7738, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7962, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8221, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7724, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8170, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7558, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7622, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7341, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7007, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7556, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6693, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7419, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6943, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7304, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7624, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7781, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7583, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7237, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7440, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7981, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7319, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7956, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7655, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7436, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7686, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7711, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7501, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7542, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7481, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7137, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7676, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7155, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6515, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7225, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7359, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7692, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7059, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6713, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7514, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7156, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7651, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7684, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7402, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7626, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7402, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7216, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7571, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6869, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7188, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7185, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6436, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7265, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7933, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7408, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7394, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7227, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6955, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7723, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7639, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7334, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6911, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7496, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7578, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7253, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7186, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7053, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7286, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7375, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7451, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7454, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6778, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6670, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7031, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7658, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7180, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7075, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7428, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7414, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7674, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6734, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7487, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7517, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7409, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7609, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7317, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8126, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7060, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7214, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7522, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7190, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7702, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7347, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7177, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6313, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7099, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7256, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6719, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7171, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7665, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7655, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6887, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7031, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7324, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8021, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8089, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7509, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6873, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7856, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6880, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7361, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7534, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7326, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7684, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7244, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7449, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7404, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7814, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7768, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7015, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7615, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7652, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7176, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7491, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7743, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6847, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7397, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7505, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7233, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6994, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7232, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7154, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7375, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6906, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7004, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8003, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7145, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7482, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7098, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7375, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7433, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7467, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7546, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7642, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7114, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6781, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7413, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7119, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6501, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7361, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6886, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7707, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7274, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7489, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7573, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7833, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8343, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(1.7807, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7788, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7163, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6665, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6727, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6861, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7854, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6955, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7019, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7213, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6727, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7310, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6858, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7761, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7201, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6809, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6943, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6979, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7316, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7010, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7288, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6848, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6728, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7451, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7024, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7578, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7934, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7033, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6962, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7194, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7156, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7489, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7718, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7049, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7096, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7653, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7339, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7322, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6758, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7144, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7971, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6490, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7157, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7491, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6909, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7306, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7157, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6955, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7233, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7043, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6895, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6971, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6574, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7644, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6982, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7173, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7077, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6893, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6812, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7548, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7515, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7471, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7314, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7146, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7265, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7115, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6847, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7231, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6709, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7488, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6666, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7516, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7330, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7050, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6651, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7109, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7254, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6839, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7287, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7327, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7359, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7089, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6842, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7484, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6822, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7041, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7364, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6784, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7133, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6602, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7323, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7320, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8016, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6921, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6823, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6904, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7171, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7582, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6966, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7432, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7395, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7474, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7258, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8061, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7223, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7213, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6314, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6822, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7098, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6708, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6553, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7326, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6799, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7130, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7852, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6759, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7064, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7732, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7456, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7853, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7724, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7218, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7449, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7037, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7559, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7463, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6871, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7699, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7493, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7454, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6778, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7263, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6954, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7866, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7888, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7020, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7181, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7290, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7339, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7118, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6681, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7345, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6598, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7106, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7057, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7221, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7294, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7134, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7258, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7338, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7101, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6679, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7054, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7697, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7569, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7701, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7647, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7441, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7846, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7771, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6807, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7283, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7211, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7751, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7412, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7337, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6924, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6945, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7694, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7599, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6777, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6891, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7291, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7055, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7101, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7247, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6773, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7648, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7363, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7105, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(1.6921, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6921, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7177, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6758, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7316, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7316, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6566, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7100, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7956, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7791, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6798, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7061, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7378, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7157, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7499, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7165, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6726, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7049, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6865, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6940, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7690, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6950, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7075, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7512, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7177, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6791, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6991, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7650, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7632, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7114, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6954, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7294, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6186, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6541, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6804, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7368, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7105, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7424, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7386, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7758, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7102, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7537, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7063, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7064, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6742, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7364, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7036, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6977, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6958, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7254, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6973, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6821, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7445, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6913, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6953, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6431, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7503, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7486, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7286, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7335, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6685, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7425, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7189, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7200, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7320, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6907, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7736, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7043, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6142, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7078, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6951, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7692, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7024, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6851, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6962, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6947, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7185, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7909, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7538, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7534, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7641, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6841, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6869, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7098, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6963, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6940, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7399, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6808, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7054, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7401, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7115, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7400, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7524, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7068, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7334, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7250, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7219, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8412, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8050, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6457, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7139, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7678, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7041, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7562, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7337, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7198, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6530, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7841, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6892, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7919, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7448, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7530, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7416, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6964, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7494, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7335, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7373, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7209, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6862, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7321, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6449, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6385, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6776, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7085, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7255, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6770, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7003, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7378, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7546, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7664, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6903, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7231, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7406, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7525, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7422, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7458, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7431, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6788, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7684, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6807, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6527, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7512, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7642, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7365, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7400, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7156, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7116, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7321, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7669, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7211, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7108, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7011, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7162, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8065, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7315, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7194, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7828, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7073, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8084, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6784, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7649, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7642, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7666, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6854, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7853, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7730, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7161, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6462, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7176, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6876, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7174, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6921, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7075, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7078, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7369, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6960, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8038, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7258, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7168, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6667, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7710, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7143, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7426, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7183, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8030, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6677, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6437, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7380, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7210, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6736, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7416, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6902, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(1.6762, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7058, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7428, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6931, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7274, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7030, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7489, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7499, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7546, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7395, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7776, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7253, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7796, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7260, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6984, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6866, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7157, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7405, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7227, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7053, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7504, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8106, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7108, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7435, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7359, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7014, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7136, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6910, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7850, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6676, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6889, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6982, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7062, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6665, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7449, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6893, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6952, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6775, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7892, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6828, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7185, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6634, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7183, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6682, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7408, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7711, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6706, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7521, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6863, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6829, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7601, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7533, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6655, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7801, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7240, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6964, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7783, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7648, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7524, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7537, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7362, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6543, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7634, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6814, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7078, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6782, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7540, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7589, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7224, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7647, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7442, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6427, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6948, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7878, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7371, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7382, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7471, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6991, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7243, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7132, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7347, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6526, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7254, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7824, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7284, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7359, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7212, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7517, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6923, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6633, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7265, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7182, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6632, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6150, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7695, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7193, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6965, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6993, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7085, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7892, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8146, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6840, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6878, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7532, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7040, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6868, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7164, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7067, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7921, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6902, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6876, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6790, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7742, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7408, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7293, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7919, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7489, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7542, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7881, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7842, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7712, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6996, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6987, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6999, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6608, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6708, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6646, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7370, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7467, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7587, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7386, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7318, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7874, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7049, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7473, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7017, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7858, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7336, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7634, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6983, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7021, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7380, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7392, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7397, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7243, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7109, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6487, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7126, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6918, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7130, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6528, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6808, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7195, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7268, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7674, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7575, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7487, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6621, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6805, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7347, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7073, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7658, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7030, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7860, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7421, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6673, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7146, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7095, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7063, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7011, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6795, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7086, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7724, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6731, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7367, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7061, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7370, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6714, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7696, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7351, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7284, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6950, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7016, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6869, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6624, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6952, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6962, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7159, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6622, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7239, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7358, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6542, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8019, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7433, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6955, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6734, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7306, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7264, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7486, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7495, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6548, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7348, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7459, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6913, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7060, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7586, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(1.7560, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6941, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6761, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7648, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6854, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7133, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7333, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7654, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6564, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6337, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7311, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7356, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7215, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6776, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7492, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7293, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6884, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7105, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7037, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6988, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7364, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7496, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7079, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7111, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7882, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7901, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7390, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6329, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6831, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7637, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7823, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7021, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7333, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6992, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7144, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7041, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6959, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7700, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6657, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7576, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7543, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6814, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7147, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6835, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6398, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7207, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6943, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7546, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7364, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6688, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7559, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7137, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7025, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7170, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7331, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6820, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7734, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6519, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7490, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7558, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7571, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7505, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7573, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7367, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7510, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7378, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7651, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7391, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6959, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7361, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6804, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7354, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7691, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7152, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7449, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7083, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6377, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7080, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6978, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6642, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6986, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7321, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7647, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6874, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7844, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7469, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6949, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7647, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6528, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6569, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6975, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7196, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7324, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7147, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6955, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7143, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7222, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7443, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7529, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7749, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6604, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6995, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7345, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7252, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7551, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7417, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7669, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6180, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6983, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7365, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7154, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6946, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7133, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7707, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6671, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6957, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7060, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7487, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7571, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7806, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6854, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7286, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7167, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6804, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7201, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6932, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7035, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7129, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6977, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7148, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7087, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7184, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6896, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6802, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6901, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7817, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7779, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7353, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7306, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7522, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7575, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6859, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7306, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7948, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7062, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7290, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7573, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6697, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7371, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7018, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6586, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6728, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7874, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7308, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6879, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7385, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6869, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7254, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7034, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7075, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6752, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7465, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7487, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7551, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7420, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7861, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7545, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6750, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7901, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7124, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7109, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7296, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7435, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6726, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7089, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6955, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7286, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7695, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7127, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6835, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7223, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7382, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7157, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7913, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7616, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7057, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6428, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7003, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7616, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6755, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7652, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6410, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6688, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6738, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6698, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7203, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6719, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7154, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7247, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6618, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6500, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7191, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6553, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6655, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6967, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7460, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7571, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7435, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6871, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7283, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6558, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6791, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.5986, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6961, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7407, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7891, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7444, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6930, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7715, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7264, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6940, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7108, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7676, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7624, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7115, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7360, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7365, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7157, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6586, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7743, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7183, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7557, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7960, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7403, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6769, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7235, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6887, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7640, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7190, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6734, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7484, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7485, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6851, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6872, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6636, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6891, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7036, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7120, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6846, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7032, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7434, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6908, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7345, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7572, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6638, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6957, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7359, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6809, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6598, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7196, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7437, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7145, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6845, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6627, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6575, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7019, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7203, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(1.7642, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6751, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7281, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7260, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7013, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6847, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7359, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6692, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7495, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7431, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6517, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7060, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7051, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7177, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6880, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7553, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7160, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7647, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7422, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7356, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6585, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7662, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6461, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7171, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6938, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7058, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7834, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7246, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7356, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7843, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7581, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7520, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8068, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7500, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7508, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6980, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7497, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7252, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7962, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6684, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7668, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6580, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7025, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7751, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7498, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7329, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7252, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6876, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7110, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7869, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7053, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6748, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6896, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6900, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7877, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6702, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7095, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7215, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7018, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6605, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7493, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6484, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6909, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7704, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7467, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7175, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6784, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8035, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7599, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7100, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7023, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6699, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7372, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6662, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8216, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6957, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7208, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7041, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7655, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6872, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7752, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7990, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7035, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6792, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7302, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6810, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7374, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6991, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7097, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6894, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8183, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7772, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6748, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6735, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7861, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6939, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7153, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6931, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7200, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6774, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7143, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7198, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7198, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8002, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7577, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6757, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7327, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7046, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6886, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7164, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7312, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7062, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7651, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7835, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7081, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7055, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6936, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7177, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7243, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7241, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7344, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6881, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7304, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7063, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6753, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6739, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6838, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7482, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7536, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7253, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7322, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6979, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6967, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7372, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7000, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7663, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6631, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7028, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6526, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7186, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6553, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7573, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6968, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7419, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7651, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6563, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7358, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7119, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6909, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6933, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7994, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.5976, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7600, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6774, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6613, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7304, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7464, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7493, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7472, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7165, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6900, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7076, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7146, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7201, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7067, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7296, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6570, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8284, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7104, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7546, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7414, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7480, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7562, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7653, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7271, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7202, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7307, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8137, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6791, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7036, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7149, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7301, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7606, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7276, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7589, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6922, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6492, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7522, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6942, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7951, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7194, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7637, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7621, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6452, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7390, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7312, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7649, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6998, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7567, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7260, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6868, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(1.6888, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6805, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6712, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7180, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6455, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7122, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6207, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7452, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6695, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7419, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7257, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6979, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7123, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6878, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6802, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6572, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7649, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7317, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7074, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7572, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7178, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7074, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6622, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6688, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7321, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7102, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7109, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6342, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7149, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7332, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7214, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7317, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7139, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7123, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6716, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6901, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6808, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7354, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7438, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7336, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7135, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6967, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6805, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7410, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6568, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7213, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.5731, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7294, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7123, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7370, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6669, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7103, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6780, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6832, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7145, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7620, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6465, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7123, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6802, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7461, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7464, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7443, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7397, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7334, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7700, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8192, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6564, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7339, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7241, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7508, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7675, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7390, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7475, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8110, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6931, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6735, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7286, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6727, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6583, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7455, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7524, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7459, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7949, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7197, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6862, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6676, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7062, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7370, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6735, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7334, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7196, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6698, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6943, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7069, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6754, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7579, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7163, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7190, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7655, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6609, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7003, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7955, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7109, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6983, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7840, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6882, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6898, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7267, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7064, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6376, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7651, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7182, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6360, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6590, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6990, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6752, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7396, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7640, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7011, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7472, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6939, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7826, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6798, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7740, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6918, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6850, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6833, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6908, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6801, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6713, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7176, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7816, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7427, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7092, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7022, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6375, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7227, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7469, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7274, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7836, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7044, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7023, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6901, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7511, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7150, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7048, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7299, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6548, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6599, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7785, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7901, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6827, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7282, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6742, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7103, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7548, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6996, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7640, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7170, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7003, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7346, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7458, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7139, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7235, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7277, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7899, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6962, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7365, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6742, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7020, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6821, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7174, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7047, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7185, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(1.7099, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7088, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7344, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6944, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7465, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7359, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6616, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6698, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7509, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7626, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6813, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6610, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6918, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6419, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7250, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6950, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7471, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7340, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6605, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6731, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6703, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6947, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6794, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7287, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7905, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6592, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7297, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7116, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7034, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7328, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7064, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6835, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7238, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7954, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6749, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7345, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7600, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7199, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7740, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7428, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7263, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6771, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7407, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6588, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6527, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7639, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7630, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6615, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6789, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6692, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7292, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7815, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7450, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6828, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7185, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7136, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6981, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7335, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7236, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7423, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7081, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6624, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7208, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7201, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7595, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6874, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6894, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7335, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7364, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7221, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7257, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7262, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6789, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6555, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7133, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7871, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7058, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6986, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6759, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6410, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6843, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6851, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6989, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6550, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6921, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6637, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6686, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7574, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6869, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7266, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7012, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6868, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7121, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6953, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7113, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6753, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7463, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7363, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6800, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6947, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7381, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7187, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7244, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7292, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7219, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6516, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6334, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6914, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7179, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6440, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7185, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7299, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7394, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7386, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7641, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7170, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7060, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7015, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7394, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6797, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7326, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7094, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7544, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7306, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7929, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7207, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7443, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7108, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7437, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6575, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7071, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7347, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7967, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7273, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6781, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7551, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6877, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7320, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7494, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7683, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7827, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6705, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7201, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6895, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7053, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7252, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6429, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7439, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7159, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7426, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7471, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7194, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6579, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7620, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7383, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7042, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7004, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6729, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6765, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7350, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7002, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7425, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7118, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7059, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7546, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7735, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7156, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7146, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7689, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6815, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7282, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7395, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7542, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7415, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7142, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6641, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6561, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6885, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7215, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7039, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6813, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7252, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6846, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7140, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7035, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7569, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7724, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7732, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7400, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7536, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6915, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7703, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7038, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6877, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6008, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7713, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7779, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7477, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7050, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6801, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7563, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7336, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6582, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7627, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7172, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7318, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6652, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7425, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7985, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(1.7881, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6974, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7683, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6479, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7043, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8136, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6722, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7369, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6878, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7948, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7637, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7894, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7632, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7073, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7365, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6922, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7699, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6731, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6823, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6424, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7382, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6788, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6484, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6694, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7053, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6953, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7378, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7376, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7517, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7021, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7262, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7003, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7576, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7270, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7189, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7161, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6768, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7608, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6672, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6844, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7284, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7133, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7108, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7515, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7016, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7065, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7163, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6695, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6553, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7655, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8004, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6634, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8048, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7060, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6910, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7019, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7729, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7507, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6532, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7048, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6773, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6977, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7447, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6967, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7229, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7180, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6676, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7222, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6495, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7636, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7247, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7204, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6948, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6956, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7375, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6729, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6769, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7821, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7766, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7248, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7364, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7825, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6858, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6873, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7605, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6572, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6553, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7533, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7381, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7148, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7454, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6848, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7028, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7776, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7113, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6848, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7575, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7467, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7392, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7055, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7070, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7590, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7455, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6120, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7635, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6934, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6951, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7906, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6937, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6850, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7257, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7468, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7202, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7774, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7123, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7299, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7448, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7841, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7502, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6671, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6776, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7579, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6932, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7546, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7555, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7682, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7492, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7357, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7312, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7425, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7397, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7888, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7411, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7583, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7242, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6869, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7358, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7524, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7257, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7214, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7102, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7462, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7264, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7410, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7517, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6899, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7331, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6665, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7622, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7166, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7384, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7453, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7408, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7544, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7479, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6703, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7977, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7660, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6583, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7711, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7055, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7098, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6346, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6663, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7426, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6901, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7545, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6322, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6869, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7087, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7730, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6952, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7383, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7315, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7136, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6656, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7281, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6816, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7273, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7794, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7185, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7419, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6931, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7306, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7854, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7121, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7382, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7318, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7390, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7015, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6807, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7384, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6768, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6963, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7666, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7019, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7631, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7124, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6745, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7393, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7461, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7407, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7561, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7618, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7266, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7797, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7200, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6700, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7822, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6917, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7088, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7993, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7462, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7320, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6409, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6489, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6978, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6728, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7023, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7709, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7736, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6474, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6967, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7475, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6971, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7293, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7025, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7737, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7172, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7473, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6715, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6959, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6788, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7491, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7366, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7306, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7372, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7498, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7242, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7086, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6662, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7689, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7046, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7035, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7561, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6463, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7146, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7258, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6605, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7313, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6619, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7184, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7206, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7350, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7040, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(1.7116, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7042, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6985, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7850, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6621, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7319, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7795, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7646, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6743, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7242, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7047, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7249, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6880, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7147, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7829, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6731, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7422, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6874, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7146, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6640, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6900, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7413, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6932, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6426, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7396, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7367, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7375, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6528, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7520, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7612, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7264, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7268, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6835, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6434, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6986, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6797, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6955, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6679, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7012, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6770, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6998, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7464, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7050, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6968, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7143, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7441, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7331, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7594, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7055, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7607, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7298, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7113, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6735, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6497, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7180, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6782, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7625, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7075, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7435, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7288, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7217, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7382, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7505, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7311, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7728, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7003, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7035, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7346, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7460, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7339, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7743, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7802, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7409, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7359, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6787, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6817, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7492, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7032, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8007, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7049, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6722, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8073, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8017, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6651, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7417, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7194, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7130, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7388, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6811, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7625, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7702, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7752, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7282, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7275, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7412, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7844, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7601, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7701, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7303, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7899, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7441, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7616, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7008, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6987, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6969, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7052, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7109, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7260, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7957, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7802, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6719, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6333, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7810, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6630, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6733, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7556, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7460, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7046, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6630, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7736, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6896, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6884, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6780, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7375, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7991, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6862, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7045, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7903, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7541, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6925, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7489, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7125, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6668, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7871, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6586, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7671, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7310, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7113, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6681, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7646, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7285, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7070, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6895, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7981, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7666, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6743, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7981, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7243, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7069, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7690, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7521, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7252, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6950, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7123, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7184, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6960, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6813, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7029, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8118, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7393, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7368, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7710, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7297, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6781, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7476, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6934, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7468, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7110, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7190, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7397, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6977, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6770, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7565, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7252, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7069, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6785, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6273, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6910, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6839, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7082, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7800, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7051, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7089, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7890, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7756, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7061, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7279, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7198, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7512, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6672, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7273, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7538, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7957, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7414, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7026, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7796, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6834, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7162, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7474, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6983, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6542, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7881, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6716, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7255, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7056, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6908, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7630, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6778, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(1.7290, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7010, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7221, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6318, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7131, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6885, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7870, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7422, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7509, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7359, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7061, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6924, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7228, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6987, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6837, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6721, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7045, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7137, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7535, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7290, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7031, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7480, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7102, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6981, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7185, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6675, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6829, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7499, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6843, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6617, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7165, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7432, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7817, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7139, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7036, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7481, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7052, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6519, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6774, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7245, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6964, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6972, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6960, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7013, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7256, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7502, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6918, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7420, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6854, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7393, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7429, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6936, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7629, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6682, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7262, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7250, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6575, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7143, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6964, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6586, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7665, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6655, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6706, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6139, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7000, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6803, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7397, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6778, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7864, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6717, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7348, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7248, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6738, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6496, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7342, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7810, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7111, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7137, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7247, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7418, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7368, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7594, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6337, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7627, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6877, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6697, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7420, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7141, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7795, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7682, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6957, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7607, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7103, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6984, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7298, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7405, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7431, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7237, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6720, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7129, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6473, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7087, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6942, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7153, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7091, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7118, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7214, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7125, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7206, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7818, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7008, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7508, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6984, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7358, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7833, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6375, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6950, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7191, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7337, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6365, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6486, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6740, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6581, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6702, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7183, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7989, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7164, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6561, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7637, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7159, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7076, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7675, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6567, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6915, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6985, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7118, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7908, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7203, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7102, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6888, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6226, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7488, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7746, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7250, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6848, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7358, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6690, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7217, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7803, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7923, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7369, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6948, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7602, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7260, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6839, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6792, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6897, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6722, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6951, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6944, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7181, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8247, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7391, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7020, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7243, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7118, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7282, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7277, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7084, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6651, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7905, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7113, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6956, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7028, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6629, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6886, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6738, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7258, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7454, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7548, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6859, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7690, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7437, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7666, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7163, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6983, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6852, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7568, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6805, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7204, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7169, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7211, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7765, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6717, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7251, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7194, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7503, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7545, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7302, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7452, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7272, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7610, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7151, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6674, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6805, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6744, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6666, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7257, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6651, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7009, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7253, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8143, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7232, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7214, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6804, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7260, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7051, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7216, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7352, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7163, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6911, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6870, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7518, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7356, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6657, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7145, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6470, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7052, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7263, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6645, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7015, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7066, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7489, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7412, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6929, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7297, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6864, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7175, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7034, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7464, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7909, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7308, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6735, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6656, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7746, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6540, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7222, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8121, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7303, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7315, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7517, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7740, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(1.7086, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6827, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7246, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7290, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7258, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6937, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7033, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7229, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7442, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6769, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7624, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7225, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7609, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7326, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7743, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7149, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7620, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7267, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7432, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6863, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6951, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7654, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6785, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7132, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7626, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7613, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7133, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7326, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7274, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6493, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7356, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6798, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7878, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7146, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7049, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6868, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6771, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7391, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6950, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6823, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6990, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7133, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7172, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6894, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7882, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7306, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7346, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6521, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6915, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7406, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7080, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6848, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6685, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7512, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7881, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7033, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7121, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6254, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6844, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6934, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7179, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7663, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7379, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7023, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6902, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7177, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7547, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7509, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6982, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8155, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6672, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6939, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7647, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7852, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7916, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7458, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7770, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7186, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7884, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7438, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7140, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7989, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7576, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7497, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7500, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7014, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7177, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7262, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7518, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7561, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7569, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7481, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6996, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7802, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6941, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6483, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6433, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7258, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6889, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6932, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7056, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7337, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7565, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6619, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6612, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7719, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6651, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7269, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7326, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6995, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6820, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7213, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7644, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7119, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6543, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7591, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7518, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7039, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7516, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7036, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6881, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7808, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7288, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6777, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7731, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7215, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7011, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7004, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7027, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7428, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7185, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6876, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7231, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6992, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7494, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6359, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7070, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7314, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7306, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6926, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6511, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7215, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7364, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7467, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7065, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7695, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6982, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7372, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6707, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6553, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6744, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8225, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7029, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7142, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7207, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7033, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6987, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7119, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6316, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6962, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7553, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7126, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6562, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6835, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7336, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7832, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7220, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7394, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7342, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7094, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7107, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7494, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7012, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6793, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6891, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7139, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7262, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6511, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7206, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6790, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7341, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7865, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7653, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7425, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7073, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7293, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7280, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7058, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7302, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6892, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7020, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7217, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7052, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7028, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7328, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6595, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7254, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7681, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7163, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  tensor(1.7747, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7020, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7144, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7164, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6923, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7496, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7389, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6565, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6565, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7653, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7350, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7266, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6725, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7097, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6927, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7010, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7087, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7234, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7514, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7334, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7482, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7128, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6420, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6243, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6925, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7598, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6736, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7111, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7210, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6898, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7040, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6462, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7397, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6552, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7339, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7226, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7624, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6964, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7246, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6658, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7421, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7563, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6897, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6612, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7578, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7608, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6762, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7152, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6807, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7943, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7074, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7315, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7298, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6755, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7240, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6946, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7520, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7423, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6880, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6919, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7572, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7707, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7385, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6586, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7669, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6671, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7265, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6587, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7126, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7177, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7299, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6906, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7353, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7586, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7119, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7367, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7470, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6806, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7109, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8080, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6878, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7489, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6583, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6568, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7080, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6707, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6822, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7266, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7709, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7323, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7438, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7847, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7429, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7761, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7436, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7850, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7107, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6642, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6833, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7929, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6743, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6683, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8127, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7148, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7923, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6736, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6770, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6810, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7425, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7574, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6802, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7360, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6758, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7639, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7577, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7244, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7272, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7007, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7434, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7212, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7307, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7949, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6891, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7324, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6903, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7249, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7694, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7180, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7277, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6889, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6522, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6775, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7398, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7859, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6927, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7015, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7928, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7237, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7115, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7083, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.8096, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6888, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7136, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7355, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7237, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7076, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7394, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7415, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7984, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6580, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6628, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7284, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7237, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6720, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7126, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7153, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7172, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7967, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6785, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7335, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6649, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7206, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7169, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6626, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7515, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6961, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7045, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6760, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7007, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6804, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6723, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7694, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.6968, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7820, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7515, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7039, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7276, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7184, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7081, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7359, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7363, grad_fn=<NllLossBackward>)\n",
      "cost:  tensor(1.7064, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for data, label in train_iter: # Traversing data loader\n",
    "        trainer.zero_grad() # Starting by resetting gradient of trainer\n",
    "        cost = loss(model(data), label) # Computing cost\n",
    "        print(\"cost: \", cost)\n",
    "        cost.sum().backward() # Backwards propagating\n",
    "        trainer.step() # performing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost so far:  tensor(1.6259, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(3.4068, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(5.1399, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(6.8742, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(8.6006, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(10.2977, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(11.9965, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(13.6860, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(15.4217, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(17.1069, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(18.8489, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(20.5515, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(22.2843, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(24.0331, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(25.7913, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(27.5064, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(29.3112, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(31.0304, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(32.7429, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(34.4492, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(36.1655, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(37.9256, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(39.7233, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(41.4122, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(43.1535, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(44.7841, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(46.4812, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(48.1909, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(49.9315, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(51.6473, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(53.3425, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(55.0788, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(56.8148, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(58.5110, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(60.2013, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(61.9448, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(63.7099, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(65.3506, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(67.0598, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(68.7894, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(70.5353, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(72.3501, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(74.0478, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(75.7506, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(77.4745, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(79.2211, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(80.9637, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(82.6955, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(84.3614, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(86.1397, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(87.8126, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(89.5362, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(91.2719, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(93.0230, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(94.7693, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(96.4557, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(98.2016, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(99.8745, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(101.7153, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(103.4525, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(105.1864, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(106.8912, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(108.6238, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(110.3889, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(112.0781, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(113.8201, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(115.4784, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(117.2361, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(118.9377, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(120.6109, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(122.3815, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(124.1081, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(125.8267, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(127.5310, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(129.3159, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(131.0568, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(132.7700, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(134.4459, grad_fn=<AddBackward0>)\n",
      "cost so far:  tensor(136.0945, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.7227, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test set prediction\n",
    "sum_cost = 0\n",
    "for test_data, test_label in test_iter:\n",
    "    sum_cost += loss(model(test_data), test_label)\n",
    "    print(\"cost so far: \", sum_cost)\n",
    "sum_cost / len(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
