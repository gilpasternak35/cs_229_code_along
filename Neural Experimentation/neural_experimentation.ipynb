{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Pick a PyTorch dataset and build a deep neural network that achieves a certain level of performance on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CIFAR10',\n",
       " 'CIFAR100',\n",
       " 'Caltech101',\n",
       " 'Caltech256',\n",
       " 'CelebA',\n",
       " 'Cityscapes',\n",
       " 'CocoCaptions',\n",
       " 'CocoDetection',\n",
       " 'DatasetFolder',\n",
       " 'EMNIST',\n",
       " 'FakeData',\n",
       " 'FashionMNIST',\n",
       " 'Flickr30k',\n",
       " 'Flickr8k',\n",
       " 'HMDB51',\n",
       " 'ImageFolder',\n",
       " 'ImageNet',\n",
       " 'KMNIST',\n",
       " 'Kinetics400',\n",
       " 'Kitti',\n",
       " 'LSUN',\n",
       " 'LSUNClass',\n",
       " 'MNIST',\n",
       " 'Omniglot',\n",
       " 'PhotoTour',\n",
       " 'Places365',\n",
       " 'QMNIST',\n",
       " 'SBDataset',\n",
       " 'SBU',\n",
       " 'SEMEION',\n",
       " 'STL10',\n",
       " 'SVHN',\n",
       " 'UCF101',\n",
       " 'USPS',\n",
       " 'VOCDetection',\n",
       " 'VOCSegmentation',\n",
       " 'VisionDataset',\n",
       " 'WIDERFace',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_utils',\n",
       " 'caltech',\n",
       " 'celeba',\n",
       " 'cifar',\n",
       " 'cityscapes',\n",
       " 'coco',\n",
       " 'fakedata',\n",
       " 'flickr',\n",
       " 'folder',\n",
       " 'hmdb51',\n",
       " 'imagenet',\n",
       " 'kinetics',\n",
       " 'kitti',\n",
       " 'lsun',\n",
       " 'mnist',\n",
       " 'omniglot',\n",
       " 'phototour',\n",
       " 'places365',\n",
       " 'sbd',\n",
       " 'sbu',\n",
       " 'semeion',\n",
       " 'stl10',\n",
       " 'svhn',\n",
       " 'ucf101',\n",
       " 'usps',\n",
       " 'utils',\n",
       " 'video_utils',\n",
       " 'vision',\n",
       " 'voc',\n",
       " 'widerface']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(torchvision.datasets) # Selecting a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data - will predict Japanese characters\n",
    "hyperparameters = {\"batch_size\": 1028, \"lr\": 0.03, \"momentum\": 0.9}\n",
    "data_transform = torchvision.transforms.ToTensor()\n",
    "kmnist_train = torchvision.datasets.KMNIST(root = \"../data\",transform = data_transform, train = True, download = True)\n",
    "kmnist_test = torchvision.datasets.KMNIST(root = \"../data\",transform = data_transform, train = False, download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset KMNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: ../data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: ToTensor(),\n",
       " Dataset KMNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ../data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: ToTensor())"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmnist_train, kmnist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building dataloaders for minibatching\n",
    "train_loader = data.DataLoader(kmnist_train, batch_size = hyperparameters[\"batch_size\"])\n",
    "test_loader = data.DataLoader(kmnist_test, batch_size = hyperparameters[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1028, 1, 28, 28])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[0].shape # Shape is 28 * 28 for inputs, doing same for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1028])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[1].shape # Checking shape of labels: is one of 1028 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Trivial Neural architecture and seeing if it can accomplish task\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
